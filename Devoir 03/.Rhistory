aggregate(smpb$n.enfant ~ smpb$prof, mean)
aggregate(n.enfant ~ prof, smpb, mean)
aggregate(smpb$n.enfant ~ smpb$prof, mean)
boxplot(n.enfant ~ prof, smpb)
m <- lm(n.enfant ~ prof, smpb)
m
drop1(m, test = "F")
m <- lm(n.enfant ~ age, smpb)
summary(m)
smp$n.enfant <- ifelse(smp$n.enfant > 2, 1, 0)
table(smp$n.enfant)
m <- glm(n.enfant ~ age, smp, family = binomial("logit"))
m2 <- glm(n.enfant ~ age, smp, family = "binomial")
Compare(m, m2)
summary(m)
summary(m2)
anova(smp$dur.interv, smp$prof)
anova(smp$dur.interv, smp$dep.cons)
anova(m1)
setwd("X:/Documentation/07-Trainings and Conferences/2019-FunMOOC Intro R/Cours")
smp <- read.csv2('smp2.csv')
View(smp)
smp$n.enfant.bin <- factor(ifelse(smp$n.enfant>2,1,0))
mod <- glm(smp$n.enfant.bin ~ age, family = 'binomial')
mod <- glm(smp$n.enfant.bin ~ smp$age, family = 'binomial')
summary(mod)
View(mod)
head(predict(m))
head(predict(mod))
head(predict(mod, type = 'response'))
log(head(predict(mod, type = 'response')))
exp(head(predict(mod)))
smp_subset <- subset(smp, smp$n.enfant >= 4 & (smp$prof == "sans emploi" | smp$prof == "ouvrier" | smp$prof == "cadre" | smp$prof == "employé"), c(age, n.enfant, prof))
View(smp_subset)
aggregate(age ~ prof, smp_subset, var)
View(smp)
View(smp_subset)
View(smp_subset)
res <- aggregate(age ~ prof, smp_subset, var)
View(res)
max(res[2])
min(res[2])
max(res[2])/min(res[2])
smp$n.fratrie.cat <- smp$n.enfant
View(smp)
ifelse(n.fratrie.cat <= 2, '0-2')
ifelse(smp$n.fratrie.cat <= 2, '0-2')
ifelse(smp$n.fratrie.cat <= 2, '0-2',)
ifelse(smp$n.fratrie.cat <= 2, '0-2', "no")
View(smp)
names(smp)
smp$n.fratrie.cat <- factor(smp$n.enfant)
View(smp)
levels(smp$n.fratrie.cat)
smp$n.fratrie.cat <- factor(smp$n.fratrie)
lecvels(smp$n.fratrie.cat)
levels(smp$n.fratrie.cat)
levels(smp$n.fratrie.cat)[1:3] <- '0-2'
levels(smp$n.fratrie.cat)
levels(smp$n.fratrie.cat)[2:3] <- '3-4'
levels(smp$n.fratrie.cat)
levels(smp$n.fratrie.cat)[3:13] <- '3-4'
table(smp$n.fratrie.cat)
table(smp$n.fratrie.cat, useNA = 'always')
levels(smp$n.fratrie.cat)
smp$n.fratrie.cat <- factor(smp$n.fratrie)
levels(smp$n.fratrie.cat)
length(levels(smp$n.fratrie.cat))
levels(smp$n.fratrie.cat)[6:21]
levels(smp$n.fratrie.cat)[6:21] <- '5+'
levels(smp$n.fratrie.cat)
levels(smp$n.fratrie.cat)[3:4] <- '3-4'
smp$n.fratrie.cat <- factor(smp$n.fratrie)
levels(smp$n.fratrie.cat)[6:21] <- '5+'
levels(smp$n.fratrie.cat)
levels(smp$n.fratrie.cat)[4:5] <- '3-4'
levels(smp$n.fratrie.cat)
levels(smp$n.fratrie.cat)[1:3] <- '0-2'
table(smp$n.fratrie.cat, smp$n.fratrie)
model <- lm(age ~ n.fratrie.cat, smp)
model
summary(model)
drop1(model, test = 'F')
model1 <- glm(smp$separation ~ smp$age, family = binomial('logit'))
model1
summary(model1)
coef(model1)
exp(coef(model1[2])
exp(coef(model1[2]))
coef(model1[2])
View(model1)
coef(model1[2])
coef(model1[1])
coef(model1)[2]
exp(coef(model1)[2])
exp(confint(model1))
confint(model1, conf.level=90)
confint(model1, conf.level=0.90)
confint(model1, level=0.90)
model2 <- lm(smp$dur.interv ~ smp$age)
summary(model2)
confint(model2)
model3 <- glm(smp$suicide.hr ~ smp$age, family = binomial)
model3 <- glm(suicide.hr ~ age, subset(smp, smp$dep.cons == 1), family = binomial)
View(model3)
summary(model3)
subset <- subset(smp, smp$dep.cons == 1)
View(subset)
model3 <- glm(suicide.hr ~ age, subset, family = binomial)
model3
summary(model3)
coef(model3)
coef(model3)[2]
exp(35*coef(model3)[2])
confint(model2, level = 0.90)
drop1(model3, test = 'chisq')
drop1(model3, 'chisq')
drop1(model3, chisq)
drop1(model3, "Chisq")
drop1(model3, test = "Chisq")
subset <- subset(smp, smp$dep.cons == 1, c('dep.cons', 'suicide.hr'))
View(subset)
subset <- subset(smp, smp$dep.cons == 1, c('dep.cons', 'suicide.hr', 'age'))
model4 <- glm(subset$suicide.hr ~ subset$age, family = binomial('logit'))
summary(model4)
predict(model4, type = 'response')
predict(model4, type = 'response')[35]
predict(model4, type = 'response')[35]
model4$coefficients
exp(model4$coefficients[1]+35*model4$coefficients[2])
exp(-0.011600788+35*(-0.009821442))
setwd("X:/Documentation/07-Trainings and Conferences/2019-FunMOOC Intro R/Cours")
alc <- read.csv2("alcool.csv")
str(alc)
View(alc)
install.packages("survival")
library(survival)
plot(survfit(Surv(alc$t, alc$SEVRE)~1), mark.time=TRUE, main="Courbe de maintien dans l'abstinence")
plot(survfit(Surv(alc$t, alc$SEVRE)~alc$SEXE), mark.time=TRUE, main="Courbe de maintien dans l'abstinence", col = c('black', 'red'))
survfit(Surv(alc$t, alc$SEVRE)~1)
summary(survfit(Surv(alc$t, alc$SEVRE)~1))
drop1(survfit(Surv(alc$t, alc$SEVRE)~1))
survdiff(Surv(t, SEVRE)~SEXE, data = alc)
coxph(Surv(t, SEVRE)~AGE, data = alc)
plot(alc$SEVRE, alc$AGE)
plot(alc$AGE, alc$SEVRE)
mod <- coxph(Surv(t, SEVRE)  ÃGE + SEXE + EDVNEG, data = alc)
mod <- coxph(Surv(t, SEVRE)  AGE + SEXE + EDVNEG, data = alc)
mod <- coxph(Surv(t, SEVRE) ~ AGE + SEXE + EDVNEG, data = alc)
mod
summary(mod)
par(mfrow = c(2, 2))
plot(cox.zph(mod))
smp <- read.csv2('smp2.csv')
var <- c('age', 'n.enfant', 'scz.cons', 'dep.cons', 'grav.cons', 'rs', 'ed', 'dr')
round(cor(smp[, var], use = 'complete.obs'), digits = '3')
round(cor(smp[,var], use = 'complete.obs'), digits = '3')
(cor(smp[,var], use = 'complete.obs'), digits = '3')
cor(smp[var], use = 'complete.obs'), digits = '3'
round(cor(smp[var], use = 'complete.obs'), digits = '3')
cor(smp[var], use = 'complete.obs')
round(cor(smp[var], use = 'complete.obs'), 3)
library(corplot)
install.packages("corplot")
library(corplot)
install.packages("corrplot")
library(corrplot)
corrplot(cor(smp[var], use = 'complete.obs'), method = 'circle')
corrplot(cor(smp[var], use = 'complete.obs'), method = 'circle')
corrplot(cor(smp[var], use = 'complete.obs'), method = 'square')
corrplot(cor(smp[var], use = 'complete.obs'), method = 'triangle')
corrplot(cor(smp[var], use = 'complete.obs'), method = 'shade')
corrplot(cor(smp[var], use = 'complete.obs'), method = 'pie')
corrplot(cor(smp[var], use = 'complete.obs'), method = 'number')
corrplot(cor(smp[var], use = 'complete.obs'), method = 'ellipse')
install.packages("psy")
library(psy)
mdspca(smp[,var])
mdspca(smp[var])
sphpca(smp[var])
fpcapca(data = smp, y = smp$grav.cons, x = smp$age + smp$n.enfant, partial = "No")
fpca(data = smp, y = smp$grav.cons, x = smp$age + smp$n.enfant, partial = "No")
View(var)
cah <- hclust(dist(t(scale(smp[,var]))), method = 'ward')
cah <- hclust(dist(t(scale(smp[,var]))), method = 'ward.D')
plot(cah)
alcool <- read.csv2('alcool.csv')
alcool$age.b <- factor(alcool$age > 50, '1', '0')
head(alcool$AGE)
alcool$age.b <- factor(alcool$AGE > 50, '1', '0')
View(alcool)
alcool$age.b <- factor(ifelse(alcool$AGE > 50, '1', '0'))
survdiff(Surv(alcool$t, alcool$SEVRE) ~ alcool$age.b)
mod <- coxph(Surv(t, SEVRE) ~ SEXE + AGE + SEXE * AGE, data = alcool)
mod
mdspca(smp[,var])
mdspca(smp[var])
sphpca(smp[var])
fpcapca(data = smp, y = smp$grav.cons, x = smp$age + smp$n.enfant, partial = "No")
fpca(data = smp, y = smp$grav.cons, x = smp$age + smp$n.enfant, partial = "No")
survdiff(Surv(t, SEVRE) ~ age.b, data = alcool)
model_suv < - survdiff(Surv(t, SEVRE) ~ age.b, data = alcool)
model_suv <- survdiff(Surv(t, SEVRE) ~ age.b, data = alcool)
model_suv
View(model_suv)
model_suv$chisq
model_suv$call
model_suv$n
summary(model_suv)
rm()
rm(alc)
rm(alcool)
rm(cah)
rm(mod)
rm(model_suv)
rm(smp)
rm(var)
savehistory("X:/Documentation/07-Trainings and Conferences/2019-FunMOOC Intro R/Cours/HistCommandes 4.R")
setwd("X:/Documentation/07-Trainings and Conferences/2019-FunMOOC Intro R/Devoirs/Devoir 03")
source('~/.active-rstudio-document', encoding = 'UTF-8')
View(data)
mod_lm <- lm(data$score.relation ~ data$age + data$score.information)
plot(mod_lm)
hist(resid(mod_lm))
mod_lm <- lm(score.relation ~ age + sexe + score.information + amelioration.sante + amelioration.moral + profession + service, data = data)
View(mod_lm)
plot(mod_lm)
plot(mod_lm)
hist(resid(mod_lm))
summary(mod_lm)
mod_lm
summary(mod_lm)
rm(mod_lm)
rm(data)
source('X:/Documentation/07-Trainings and Conferences/2019-FunMOOC Intro R/Devoirs/Devoir 03/Devoir03.R')
source('X:/Documentation/07-Trainings and Conferences/2019-FunMOOC Intro R/Devoirs/Devoir 03/Devoir03.R')
source('X:/Documentation/07-Trainings and Conferences/2019-FunMOOC Intro R/Devoirs/Devoir 03/Devoir03.R')
print(summary(model_lm))
source('X:/Documentation/07-Trainings and Conferences/2019-FunMOOC Intro R/Devoirs/Devoir 03/Devoir03.R')
# Question 1: Estimez le modèle de régression linéaire expliquant la variable « score.relation »
# par les variables « age », « sexe », « score.information », « amelioration.sante »,
# « amelioration.moral », « profession »,  « service ».
# (Le script doit inclure la vérification éventuelle des conditions de validité de la méthode utilisée.)
model_lm <- lm(score.relation ~ age + sexe + score.information + amelioration.sante + amelioration.moral + profession + service, data = data)
print(summary(model_lm)) # Affichage du modèle
# Question 1: Estimez le modèle de régression linéaire expliquant la variable « score.relation »
# par les variables « age », « sexe », « score.information », « amelioration.sante »,
# « amelioration.moral », « profession »,  « service ».
# (Le script doit inclure la vérification éventuelle des conditions de validité de la méthode utilisée.)
model_lm <- lm(score.relation ~ age + sexe + score.information + amelioration.sante + amelioration.moral + profession + service, data = data)
summary(model_lm) # Affichage du modèle
# Conditions de validité du modèle de régression :
#   1) Normalité des résidus (ou bruit)
#   2) Variance bruit indépendante de valeurs de la variable à expliquer et des des valeurs des variables explicatives
#   3) Bruit: Pas de structure de corrélation évidente, de structure de corrélation interne.
# En pratique les 2 dernières conditions sont difficiles à vérifier.
# On se contente de vérifier la normalité de la distribution des résidus
hist(resid(model_lm))
data$recommader.b <- factor(ifelse(data$recommander < 2, '0', '1'))
table(data$recommader.b, data$recommander)
table(data$recommader.b, data$recommander, useNA = 'alwas')
table(data$recommader.b, data$recommander, useNA = 'always')
xtabs(data$recommader.b ~ data$recommander)
model_logistique <- glm(recommander.b ~ age + sexe + score.information + amelioration.sante + amelioration.moral + profession + service, data = data, family = 'binomial')
rm(data9)
rm(data)
rm(model_lm)
# Chargement données
data <- read.csv2('satisfaction_hopital.csv')
# Question 1: Estimez le modèle de régression linéaire expliquant la variable « score.relation »
# par les variables « age », « sexe », « score.information », « amelioration.sante »,
# « amelioration.moral », « profession »,  « service ».
# (Le script doit inclure la vérification éventuelle des conditions de validité de la méthode utilisée.)
model_lm <- lm(score.relation ~ age + sexe + score.information + amelioration.sante + amelioration.moral + profession + service, data = data)
summary(model_lm) # Affichage du modèle
# Conditions de validité du modèle de régression :
#   1) Normalité des résidus (ou bruit)
#   2) Variance bruit indépendante de valeurs de la variable à expliquer et des des valeurs des variables explicatives
#   3) Bruit: Pas de structure de corrélation évidente, de structure de corrélation interne.
# En pratique les 2 dernières conditions sont difficiles à vérifier.
# On se contente de vérifier la normalité de la distribution des résidus
hist(resid(model_lm))
# Conditions de validité du modèle de régression :
#   1) Normalité des résidus (ou bruit)
#   2) Variance bruit indépendante de valeurs de la variable à expliquer et des des valeurs des variables explicatives
#   3) Bruit: Pas de structure de corrélation évidente, de structure de corrélation interne.
# En pratique les 2 dernières conditions sont difficiles à vérifier.
# On se contente de vérifier la normalité de la distribution des résidus
hist(resid(model_lm))
# Question 2: Estimez le modèle de régression logistique expliquant la variable « recommander.b »
# par les variables « age », « sexe », « score.information », « amelioration.sante »,
# « amelioration.moral », « profession »,  « service ».
# Notons que la variable « recommander.b » est une transformation de la variable « recommander »
# en une variable binaire où « recommander.b » vaut 0 si « recommander » vaut 0 ou 1,
# et 1 si « recommander » vaut 2.
# (Le script doit inclure la vérification éventuelle des conditions de validité de la
# méthode utilisée)
data$recommander.b <- factor(ifelse(data$recommander < 2, '0', '1')) # recodage variable "recommander" en variable binaire "recommande.b"
model_logistique <- glm(recommander.b ~ age + sexe + score.information + amelioration.sante + amelioration.moral + profession + service, data = data, family = 'binomial')
summary(model_logistique)
View(model_lm)
View(model_logistique)
rm(data)
rm(model_lm, model_logistique)
# Chargement données
data <- read.csv2('satisfaction_hopital.csv')
# Création d'un modèle de régression linéaire multiple
model_lm <- lm(score.relation ~ age + sexe + score.information + amelioration.sante + amelioration.moral + profession + service, data = data)
summary(model_lm) # Affichage du modèle
# Conditions de validité du modèle de régression linéeaire multiple :
#   1) Normalité des résidus (ou bruit)
#   2) Variance bruit indépendante de valeurs de la variable à expliquer et des des valeurs des variables explicatives
#   3) Bruit: Pas de structure de corrélation évidente, de structure de corrélation interne.
# En pratique les 2 dernières conditions sont difficiles à vérifier.
# On se contente de vérifier la normalité de la distribution des résidus
hist(resid(model_lm))
# Question 2: Estimez le modèle de régression logistique expliquant la variable « recommander.b »
# par les variables « age », « sexe », « score.information », « amelioration.sante »,
# « amelioration.moral », « profession »,  « service ».
# Notons que la variable « recommander.b » est une transformation de la variable « recommander »
# en une variable binaire où « recommander.b » vaut 0 si « recommander » vaut 0 ou 1,
# et 1 si « recommander » vaut 2.
# (Le script doit inclure la vérification éventuelle des conditions de validité de la
# méthode utilisée)
data$recommander.b <- factor(ifelse(data$recommander < 2, '0', '1')) # recodage variable "recommander" en variable binaire "recommander.b"
summary(model_logistique) # Affichage du modèle
model_logistique <- glm(recommander.b ~ age + sexe + score.information + amelioration.sante + amelioration.moral + profession + service, data = data, family = 'binomial')
summary(model_logistique) # Affichage du modèle
table(data$recommander.b, useNA = 'always')
tab <- table(data$recommander.b, useNA = 'always')
tab[2]
tab[2, 2]
tab[2; 2]
tab[2 2]
str(data)
data$service <- factor(data$service)
data$sexe <- factor(data$sexe)
data$profession <- factor(data$profession)
str(data)
rm(data model_lm model_logistique tab)
rm(data, model_lm, model_logistique, tab)
# Chargement données
data <- read.csv2('satisfaction_hopital.csv')
# Création d'un modèle de régression linéaire multiple
data$service <- factor(data$service) # Recodage en variable catégorielle
data$sexe <- factor(data$sexe) # Recodage en variable catégorielle
data$profession <- factor(data$profession) # Recodage en variable catégorielle
data$profession <- factor(data$profession) # Recodage en variable catégorielle
str(data)
model_lm <- lm(score.relation ~ age + sexe + score.information + amelioration.sante + amelioration.moral + profession + service, data = data)
summary(model_lm) # Affichage du modèle
summary(model_lm) # Affichage du modèle
# Conditions de validité du modèle de régression linéeaire multiple :
#   1) Normalité des résidus (ou bruit)
#   2) Variance bruit indépendante de valeurs de la variable à expliquer et des des valeurs des variables explicatives
#   3) Bruit: Pas de structure de corrélation évidente, de structure de corrélation interne.
# En pratique les 2 dernières conditions sont difficiles à vérifier.
# On se contente de vérifier la normalité de la distribution des résidus
hist(resid(model_lm))
plot(model_lm)
# Conditions de validité du modèle de régression linéeaire multiple :
#   1) Normalité des résidus (ou bruit)
#   2) Variance bruit indépendante de valeurs de la variable à expliquer et des des valeurs des variables explicatives
#   3) Bruit: Pas de structure de corrélation évidente, de structure de corrélation interne.
# En pratique les 2 dernières conditions sont difficiles à vérifier.
# On se contente de vérifier la normalité de la distribution des résidus
hist(resid(model_lm))
# Création d'un modèle de régression logistique
data$recommander.b <- factor(ifelse(data$recommander < 2, '0', '1')) # recodage variable "recommander" en variable binaire "recommander.b"
model_logistique <- glm(recommander.b ~ age + sexe + score.information + amelioration.sante + amelioration.moral + profession + service, data = data, family = 'binomial')
summary(model_logistique) # Affichage du modèle
levels(data$sexe)
nlevels(data$sexe)
nlevels(data$age)
nlevels(data$service)
nlevels(data$profession)
tab(data$recommander.b)
tab <- table(data$recommander.b)
tab
tab[2][2]
tab[1][2]
tab[1]
tab[2][1]
tab[1, 1]
tab[1, "0"]
tab[1]
tab[2]
tab[2][2]
tab[2][1]
tab[2, 2]
summary(model_logistique) # Affichage du modèle
# Conditions de validité du modèle de régression logistique :
# Au moins 5 à 10 évènements par varibale explicative
table(recommander.b, useNA = 'always') # tableau d'effectifs
# Conditions de validité du modèle de régression logistique :
# Au moins 5 à 10 évènements par varibale explicative
table(data$recommander.b, useNA = 'always') # tableau d'effectifs
# On constate que 269 sujet ont donné le score recommander.b = 1
# Comptage du nombre de variables
N_var = 1 + (nlevels(data$sexe) - 1) + 1 + 1 + 1 + (nleves(data$profession) - 1) + (nlevels(data$service))
# On constate que 269 sujet ont donné le score recommander.b = 1
# Comptage du nombre de variables
N_var = 1 + (nlevels(data$sexe) - 1) + 1 + 1 + 1 + (nlevels(data$profession) - 1) + (nlevels(data$service))
N_var * 10
N_var * 5
rm(data, model_lm, model_logistique, tab)
# Chargement données
data <- read.csv2('satisfaction_hopital.csv')
library(utils)
library(stats)
# Création d'un modèle de régression linéaire multiple
data$service <- factor(data$service) # Recodage en variable catégorielle
data$sexe <- factor(data$sexe) # Recodage en variable catégorielle
data$profession <- factor(data$profession) # Recodage en variable catégorielle
str(data)
model_lm <- lm(score.relation ~ age + sexe + score.information + amelioration.sante + amelioration.moral + profession + service, data = data)
summary(model_lm) # Affichage du modèle
# Conditions de validité du modèle de régression linéeaire multiple :
#   1) Normalité des résidus (ou bruit)
#   2) Variance bruit indépendante de valeurs de la variable à expliquer et des des valeurs des variables explicatives
#   3) Bruit: Pas de structure de corrélation évidente, de structure de corrélation interne.
# En pratique les 2 dernières conditions sont difficiles à vérifier.
# On se contente de vérifier la normalité de la distribution des résidus
hist(resid(model_lm))
# Création d'un modèle de régression logistique
data$recommander.b <- factor(ifelse(data$recommander < 2, '0', '1')) # recodage variable "recommander" en variable binaire "recommander.b"
model_logistique <- glm(recommander.b ~ age + sexe + score.information + amelioration.sante + amelioration.moral + profession + service, data = data, family = 'binomial')
summary(model_logistique) # Affichage du modèle
# Conditions de validité du modèle de régression logistique :
# Au moins 5 à 10 évènements par variable explicative
table(data$recommander.b, useNA = 'always') # tableau d'effectifs
# On constate que 269 sujet ont donné le score recommander.b = 1
# Comptage du nombre de variables
N_var = 1 + (nlevels(data$sexe) - 1) + 1 + 1 + 1 + (nlevels(data$profession) - 1) + (nlevels(data$service))
N_var * 10 # Nombre minimum d'évènements en prenant comme règle 10 évènements/variable explicative
# On constate que 269 sujets ont donné le score recommander.b = 1
# Comptage du nombre de variables
N_var = 1 + (nlevels(data$sexe) - 1) + 1 + 1 + 1 + (nlevels(data$profession) - 1) + (nlevels(data$service))
N_var * 10 # Nombre minimum d'évènements en prenant comme règle 10 évènements/variable explicative
N_var * 5 # Nombre minimum d'évènements en prenant comme règle 5 évènements/variable explicative
# On constate que 269 sujets ont donné le score recommander.b = 1
# Comptage du nombre de variables
N_var = 1 + (nlevels(data$sexe) - 1) + 1 + 1 + 1 + (nlevels(data$profession) - 1) + (nlevels(data$service))
N_var * 10 # Nombre minimum d'évènements en prenant comme règle 10 évènements/variable explicative
N_var * 5 # Nombre minimum d'évènements en prenant comme règle 5 évènements/variable explicative
# Dans notre cas, nous avons 269 évènements pour un minimum de 200. Le modèle peut donc être considéré comme valide.
# Dans notre cas, nous avons 269 évènements pour un minimum de 200. Le modèle peut donc être considéré comme valide.
# Dans notre cas, nous avons 269 évènements pour un minimum de 200. Le modèle peut donc être considéré comme valide.
# Chargement données
data <- read.csv2('satisfaction_hopital.csv')
library(utils)
library(stats)
# Création d'un modèle de régression linéaire multiple
data$service <- factor(data$service) # Recodage en variable catégorielle
data$sexe <- factor(data$sexe) # Recodage en variable catégorielle
data$profession <- factor(data$profession) # Recodage en variable catégorielle
model_lm <- lm(score.relation ~ age + sexe + score.information + amelioration.sante + amelioration.moral + profession + service, data = data)
summary(model_lm) # Affichage du modèle
# Conditions de validité du modèle de régression linéeaire multiple :
#   1) Normalité des résidus (ou bruit)
#   2) Variance bruit indépendante de valeurs de la variable à expliquer et des des valeurs des variables explicatives
#   3) Bruit: Pas de structure de corrélation évidente, de structure de corrélation interne.
# En pratique les 2 dernières conditions sont difficiles à vérifier.
# On se contente de vérifier la normalité de la distribution des résidus
hist(resid(model_lm))
# Création d'un modèle de régression logistique
data$recommander.b <- factor(ifelse(data$recommander < 2, '0', '1')) # recodage variable "recommander" en variable binaire "recommander.b"
model_logistique <- glm(recommander.b ~ age + sexe + score.information + amelioration.sante + amelioration.moral + profession + service, data = data, family = 'binomial')
summary(model_logistique) # Affichage du modèle
# Conditions de validité du modèle de régression logistique :
# Au moins 5 à 10 évènements par variable explicative
table(data$recommander.b, useNA = 'always') # tableau d'effectifs
# On constate que 269 sujets ont donné le score recommander.b = 1
# Comptage du nombre de variables
N_var = 1 + (nlevels(data$sexe) - 1) + 1 + 1 + 1 + (nlevels(data$profession) - 1) + (nlevels(data$service))
# On constate que 269 sujets ont donné le score recommander.b = 1
# Comptage du nombre de variables
N_var = 1 + (nlevels(data$sexe) - 1) + 1 + 1 + 1 + (nlevels(data$profession) - 1) + (nlevels(data$service) - 1)
N_var * 10 # Nombre minimum d'évènements en prenant comme règle 10 évènements/variable explicative
N_var * 5 # Nombre minimum d'évènements en prenant comme règle 5 évènements/variable explicative
# Dans notre cas, nous avons 269 évènements pour un minimum de 200. Le modèle peut donc être considéré comme valide.
# Chargement données
data <- read.csv2('satisfaction_hopital.csv')
library(utils)
library(stats)
# Création d'un modèle de régression linéaire multiple
data$service <- factor(data$service) # Recodage en variable catégorielle
data$sexe <- factor(data$sexe) # Recodage en variable catégorielle
data$profession <- factor(data$profession) # Recodage en variable catégorielle
model_lm <- lm(score.relation ~ age + sexe + score.information + amelioration.sante + amelioration.moral + profession + service, data = data)
summary(model_lm) # Affichage du modèle
# Conditions de validité du modèle de régression linéeaire multiple :
#   1) Normalité des résidus (ou bruit)
#   2) Variance bruit indépendante de valeurs de la variable à expliquer et des des valeurs des variables explicatives
#   3) Bruit: Pas de structure de corrélation évidente, de structure de corrélation interne.
# En pratique les 2 dernières conditions sont difficiles à vérifier.
# On se contente de vérifier la normalité de la distribution des résidus
hist(resid(model_lm))
# Création d'un modèle de régression logistique
data$recommander.b <- factor(ifelse(data$recommander < 2, '0', '1')) # recodage variable "recommander" en variable binaire "recommander.b"
model_logistique <- glm(recommander.b ~ age + sexe + score.information + amelioration.sante + amelioration.moral + profession + service, data = data, family = 'binomial')
summary(model_logistique) # Affichage du modèle
# Conditions de validité du modèle de régression logistique :
# Au moins 5 à 10 évènements par variable explicative
table(data$recommander.b, useNA = 'always') # tableau d'effectifs
# On constate que 269 sujets ont donné le score recommander.b = 1
# Comptage du nombre de variables
N_var = 1 + (nlevels(data$sexe) - 1) + 1 + 1 + 1 + (nlevels(data$profession) - 1) + (nlevels(data$service) - 1)
N_var * 10 # Nombre minimum d'évènements en prenant comme règle 10 évènements/variable explicative
N_var * 5 # Nombre minimum d'évènements en prenant comme règle 5 évènements/variable explicative
# Dans notre cas, nous avons 269 évènements pour un minimum de 200. Le modèle peut donc être considéré comme valide.
savehistory("X:/Documentation/07-Trainings and Conferences/2019-FunMOOC Intro R/Cours/HistCommandes 5.R")
